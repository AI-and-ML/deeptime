{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sktime\n",
    "import sktime.decomposition.vampnet as vnet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sktime.data.ellipsoids().observations(100000, n_dim=150).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 1\n",
    "data_0 = data[:-tau]\n",
    "data_t = data[tau:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lobe(nn.Module):\n",
    "    \n",
    "    def __init__(self, fan_in, fan_out, n_hidden=5):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(fan_in, 150), nn.ELU(), nn.BatchNorm1d(150)] \\\n",
    "                 + [nn.Linear(150, 150), nn.ELU()]*(n_hidden -1) \\\n",
    "                 + [nn.Linear(150, fan_out), nn.Softmax(1)]\n",
    "        self._seq = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return self._seq(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lobe = Lobe(150, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(lobe.parameters(), lr=5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    ix = np.random.permutation(len(data_0))\n",
    "    data_0 = data_0[ix]\n",
    "    data_t = data_t[ix]\n",
    "    \n",
    "    lvals = []\n",
    "    for batch_ix in sktime.data.timeshifted_split(np.arange(len(data_0)), \n",
    "                                                  chunksize=batch_size, lagtime=0):\n",
    "        batch_0 = torch.from_numpy(data_0[batch_ix])\n",
    "        batch_t = torch.from_numpy(data_t[batch_ix])\n",
    "        \n",
    "        x_0 = lobe(batch_0)\n",
    "        x_t = lobe(batch_t)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss = vnet.loss_vamp2(x_0, x_t)\n",
    "        lvals.append(loss.detach().cpu().numpy())\n",
    "        loss.backward()\n",
    "    print(np.mean(lvals))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
