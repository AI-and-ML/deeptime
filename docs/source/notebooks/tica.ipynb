{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TICA\n",
    "\n",
    "For users already familiar with the TICA interface: The corresponding [API docs](../api/generated/deeptime.decomposition.TICA.rst#deeptime.decomposition.TICA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TICA <cite data-cite=\"nbtica-molgedey1994separation\">(Molgedey, 1994)</cite> is short for Time-lagged Independent Component Analysis (sometimes also time structure-based ICA) and is a linear transformation method that can be used for dimensionality reduction. It was introduced for molecular dynamics in <cite data-cite=\"nbtica-naritomi2011slow\">(Naritomi, 2011)</cite>, later <cite data-cite=\"nbtica-perez2013identification\">(Pérez-Hernández, 2013)</cite> and as a method in the pipeline of Markov model construction in <cite data-cite=\"nbtica-perez2013identification\">(Pérez-Hernández, 2013)</cite> and <cite data-cite=\"nbtica-schwantes2013improvements\">(Schwantes, 2013)</cite>.\n",
    "\n",
    "TICA is algorithmically identical to extended dynamic mode decomposition (EDMD) <cite data-cite=\"nbtica-williams2015data\">(Williams, 2015)</cite>, which is in pracitice also used to analyze time series which are not in detailed balance, yielding complex-valued eigenfunctions.\n",
    "\n",
    "> The input for the TICA algorithm is a time-series dataset. Due to the linear nature of the method it can help, to first featurize the input data by passing it through nonlinear functions. This could be for example pairwise distances in case the input is based on molecular dynamics data.\n",
    "\n",
    "When the input data is the result of a Markov process, TICA finds in fact an approximation to the eigenfunctions and eigenvalues of the underlying Markov operator <cite data-cite=\"nbtica-perez2013identification\">(Pérez-Hernández, 2013)</cite>.\n",
    "\n",
    "To that end, it maps the data to the \"slow\" processes, i.e., it finds the coordinates of maximal autocorrelation at a given lag time $\\tau$.\n",
    "\n",
    "Given a sequence of multivariate data $X_t$, it computes the mean-free covariance and time-lagged covariance matrix\n",
    "\n",
    "$$\\begin{aligned}\n",
    "C_0 &=      (X_t - \\mu)^T \\mathrm{diag}(w) (X_t - \\mu), \\\\\n",
    "C_{\\tau} &= (X_t - \\mu)^T \\mathrm{diag}(w) (X_{t + \\tau} - \\mu),\n",
    "\\end{aligned}$$\n",
    "\n",
    "where $w$ is a vector of weights for each time step. Optionally, one can use the reversible estimate by using symmetrized correlation matrices\n",
    "\n",
    "$$ \\sum_t X_t + X_{t+\\tau} $$\n",
    "\n",
    "and second moment matrices defined by\n",
    "\n",
    "$$ X_t^\\top X_t + X_{t+\\tau}^\\top X_{t+\\tau} \\;\\text{ and }\\; X_{t+\\tau}^\\top X_t + X_t^\\top X_{t+\\tau}. $$\n",
    "\n",
    "By default, the weights $w$ are all equal to one, but different weights are possible, like the re-weighting\n",
    "to equilibrium described in <cite data-cite=\"nbtica-wu2017variational\">(Wu, 2017)</cite>. Subsequently, the eigenvalue problem\n",
    "\n",
    "$$ C_{\\tau} r_i = C_0 \\lambda_i r_i $$\n",
    "\n",
    "is solved,where $r_i$ are the independent components and $\\lambda_i$ are their respective normalized time-autocorrelations. The eigenvalues are related to the relaxation timescale by\n",
    "\n",
    "$$ t_i = -\\frac{\\tau}{\\ln |\\lambda_i|}. $$\n",
    "\n",
    "When used as a dimension reduction method, the input data is projected onto the dominant independent components. Since the eigenvalues $\\lambda_i$ are indicators of the slowness of their respective processes, these dominant components belong to the slowest processes in the data. \n",
    "\n",
    "When the underlying operator is defined on a compact domain (e.g., in Euclidean spaces this is equivalent to a closed and bounded subset like closed intervals), the spectrum of the operator is discrete <cite data-cite=\"nbtica-landau2013quantum\">(Landau, 2013)</cite>. In that case one can ask whether there is a \"spectral gap\" (with which we mean a gap within the ordered sequence of eigenvalues which is significant). Eigenvalues which are larger than said gap would belong to \"slow\" (per association to timescales) processes in the system, eigenvalues lower than the gap belong to fast processes.\n",
    "\n",
    "Said spectral gap can help with the decision of the number of dimensions to project onto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:13.876586Z",
     "iopub.status.busy": "2020-10-26T12:13:13.874985Z",
     "iopub.status.idle": "2020-10-26T12:13:14.592544Z",
     "shell.execute_reply": "2020-10-26T12:13:14.592051Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np  # NumPy for general numerical operations\n",
    "import deeptime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a time series, default TICA can be applied by calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:14.595798Z",
     "iopub.status.busy": "2020-10-26T12:13:14.595443Z",
     "iopub.status.idle": "2020-10-26T12:13:14.597796Z",
     "shell.execute_reply": "2020-10-26T12:13:14.597408Z"
    }
   },
   "outputs": [],
   "source": [
    "tica = deeptime.decomposition.TICA(lagtime=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yielding an estimator which operates on symmetrized correlation matrices and takes as many eigenvalues as required to capture 95% of the kinetic variance of the time series.\n",
    "\n",
    "It can be fit by calling [fit()](../api/generated/deeptime.decomposition.TICA.rst#deeptime.decomposition.TICA.fit). This method distinguishes between arguments which are covariance matrices in form of a symmetrized [CovarianceModel](../api/generated/deeptime.covariance.CovarianceModel.rst#deeptime.covariance.CovarianceModel) and raw timeseries data. In case of raw timeseries data, the lagtime $\\tau$ must be provided, otherwise it is inferred from the covariance model.\n",
    "\n",
    "_Note_: TICA makes reversible estimates and then assumes, that the data is in equilibrium. In case of reversible estimate but non-equilibrium data (e.g., many short trajectories which start off-equilibrium), [Koopman reweighting](#Koopman-reweighting) can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:14.601714Z",
     "iopub.status.busy": "2020-10-26T12:13:14.600993Z",
     "iopub.status.idle": "2020-10-26T12:13:14.611206Z",
     "shell.execute_reply": "2020-10-26T12:13:14.611594Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.random.uniform(size=(1000, 5))\n",
    "tica.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, covariances can be estimated and then used to fit the estimator. The [covariance_estimator](../api/generated/deeptime.decomposition.TICA.rst#deeptime.decomposition.TICA.covariance_estimator) method yields a [Covariance](../api/generated/deeptime.covariance.Covariance.rst#deeptime.covariance.Covariance) estimator which is properly configured for TICA (i.e., it symmetrizes the covariances and computes $C_{00} = C_{tt}$ and $C_{0t}$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:14.615245Z",
     "iopub.status.busy": "2020-10-26T12:13:14.614648Z",
     "iopub.status.idle": "2020-10-26T12:13:14.619101Z",
     "shell.execute_reply": "2020-10-26T12:13:14.618710Z"
    }
   },
   "outputs": [],
   "source": [
    "covariances = deeptime.decomposition.TICA.covariance_estimator(lagtime=1) \\\n",
    "    .fit(data)\n",
    "tica.fit(covariances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can be obtained by a call to [fetch_model()](../api/generated/deeptime.decomposition.TICA.rst#deeptime.decomposition.TICA.fetch_model) in order to transform / project data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:14.622929Z",
     "iopub.status.busy": "2020-10-26T12:13:14.622433Z",
     "iopub.status.idle": "2020-10-26T12:13:14.625082Z",
     "shell.execute_reply": "2020-10-26T12:13:14.624689Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tica.fetch_model()\n",
    "projection = model.transform(np.random.uniform(size=(500, 5)))\n",
    "print(projection.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details, please see below examples as well as the [API docs](../api/generated/deeptime.decomposition.TICA.rst#deeptime.decomposition.TICA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison vs. PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To highlight the advantages TICA can possess over Principle Component Analysis (PCA), we consider the following example setup:\n",
    "\n",
    "We generate a synthetic trajectory of observations of states $S = \\{0, 1\\}$ which is generated from a Markov state model (see [here](../index_msm.rst) for documentation on Markov state models). The only important thing for now is that it contains conditional probability to go from one state to another, i.e., given a transition matrix\n",
    "$$\n",
    "P = \\begin{pmatrix} 0.97 & 0.03 \\\\ 0.03 & 0.97 \\end{pmatrix}\n",
    "$$\n",
    "we have a probability $P_{11} = 97\\%$ to stay in state \"0\" and a $P_{12} = 3\\%$ to transition from state \"0\" to state \"1\" and vice versa. \n",
    "\n",
    "We map the state sequence into ellipsoidal shapes in 2-dimensional space. For more details, please see the example data's [documentation](../api/generated/impl/deeptime.data.ellipsoids_dataset.Ellipsoids.rst#deeptime.data.ellipsoids_dataset.Ellipsoids)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:14.630107Z",
     "iopub.status.busy": "2020-10-26T12:13:14.629298Z",
     "iopub.status.idle": "2020-10-26T12:13:14.633164Z",
     "shell.execute_reply": "2020-10-26T12:13:14.633554Z"
    }
   },
   "outputs": [],
   "source": [
    "# create dataset instance\n",
    "ellipsoids = deeptime.data.ellipsoids(seed=17)\n",
    "# discrete transitions\n",
    "discrete_trajectory = ellipsoids.discrete_trajectory(n_steps=1000)\n",
    "# corresponding observations\n",
    "feature_trajectory = ellipsoids.map_discrete_to_observations(discrete_trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporally, a relatively long time is spent in either of these distributions before jumping to the other.\n",
    "\n",
    "This can be observed also in the two-dimensional right-hand plot: The data is supersampled (each consecutive point-pair in the time series is linearly interpolated with 50 interpolation points) so that transition jumps become visible; these transitions are significantly lower intensity than the ellipsoids. If jumps were frequent, the in-between region would be much brighter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:14.639919Z",
     "iopub.status.busy": "2020-10-26T12:13:14.639264Z",
     "iopub.status.idle": "2020-10-26T12:13:15.684225Z",
     "shell.execute_reply": "2020-10-26T12:13:15.683816Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # plotting\n",
    "f, axes = plt.subplots(1, 3, figsize=(12, 5), constrained_layout=True)\n",
    "ax1, ax2, ax3 = axes.flat\n",
    "\n",
    "# discrete trajectory\n",
    "ax1.plot(discrete_trajectory)\n",
    "ax1.set_xlabel('time')\n",
    "ax1.set_ylabel('state')\n",
    "ax1.set_title('Sequence of states from Markov state model');\n",
    "\n",
    "# scatter plot of samples\n",
    "ax2.scatter(*(feature_trajectory.T), marker='.')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_title('Example data samples')\n",
    "\n",
    "# interpolate ftraj so that 50 times more steps are made and transitions become visible\n",
    "# in heatmap representation\n",
    "n_interp = 50\n",
    "n_steps = len(discrete_trajectory)\n",
    "xs = np.arange(n_steps, step=1./n_interp)\n",
    "ftraj_interp = np.empty((n_steps*n_interp, 2))\n",
    "ftraj_interp[:, 0] = np.interp(xs, np.arange(n_steps), feature_trajectory[:, 0])\n",
    "ftraj_interp[:, 1] = np.interp(xs, np.arange(n_steps), feature_trajectory[:, 1])\n",
    "\n",
    "# heatmap\n",
    "hb = ax3.hexbin(ftraj_interp[:, 0], ftraj_interp[:, 1], bins='log')\n",
    "f.colorbar(hb, ax=ax3)\n",
    "ax3.set_xlabel('x')\n",
    "ax3.set_ylabel('y')\n",
    "ax3.set_title('Supersampled example data in log-heatmap');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we project back into one dimension with PCA, the result contains basically no signal: PCA finds the axis that maximizes variance, which is along long axis of the ellipsoids and completely ignores temporal information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:15.689736Z",
     "iopub.status.busy": "2020-10-26T12:13:15.689345Z",
     "iopub.status.idle": "2020-10-26T12:13:15.904752Z",
     "shell.execute_reply": "2020-10-26T12:13:15.904330Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1).fit(feature_trajectory)  # fit the 2-dimensional data\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "projection = pca.transform(feature_trajectory)\n",
    "ax1.plot(projection)\n",
    "ax1.set_title('PCA projection of 2-dimensional trajectory')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('t')\n",
    "\n",
    "dxy = pca.components_[0]  # dominant pca component\n",
    "\n",
    "ax2.scatter(*(feature_trajectory.T), marker='.')\n",
    "x, y = np.meshgrid(\n",
    "    np.linspace(np.min(feature_trajectory[:, 0]), np.max(feature_trajectory[:, 0]), 4),\n",
    "    np.linspace(np.min(feature_trajectory[:, 1]), np.max(feature_trajectory[:, 1]), 4)\n",
    ")\n",
    "plt.quiver(x,y,dxy[0],dxy[1])\n",
    "\n",
    "ax2.set_aspect('equal')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_title('Example data samples with dominant PCA component');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, projecting with TICA takes temporal information into account and finds the dominant slow direction, i.e., the rare transition between the two distributions.\n",
    "\n",
    "We create a TICA estimator, parameterized by the `lagtime`, which is the time shift $\\tau$ for which autocorrelations are taken into account, and `dim`, which is the dimension. Here, the dimension can either be an `int` , a `float`, or `None` - each having significant influence on how the projection dimension is determined:\n",
    "\n",
    "- in case `dim` is `None`, all available ranks are kept;\n",
    "- in case `dim` is an integer (like in this case), it must be positive and fixes the projection dimension to the given value;\n",
    "- in case `dim` is a floating point value (e.g., `TICA(..., dim=0.7)`), it must be `0 < dim <= 1`. Then, it selects the number of dimensions such that the amount of kinetic variance that needs to be explained is greater than the percentage specified by dim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:15.907919Z",
     "iopub.status.busy": "2020-10-26T12:13:15.907531Z",
     "iopub.status.idle": "2020-10-26T12:13:15.909875Z",
     "shell.execute_reply": "2020-10-26T12:13:15.909470Z"
    }
   },
   "outputs": [],
   "source": [
    "tica = deeptime.decomposition.TICA(\n",
    "    dim=1,  # fix projection dimension explicitly\n",
    "    lagtime=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the [tica model](../api/generated/deeptime.decomposition.CovarianceKoopmanModel.rst#deeptime.decomposition.CovarianceKoopmanModel) can be estimated.\n",
    "\n",
    "_Note_: In the reversible (default) case, this assumes that the data comes from an equilibirum distribution. Applying the method as-is to short off-equilibrium data produces heavily biased estimates. See [Koopman reweighting](#Koopman-reweighting) (or the corresponding [API docs](../api/generated/deeptime.covariance.KoopmanWeightingEstimator.rst#deeptime.covariance.KoopmanWeightingEstimator)) for a reweighting technique that extends TICA to non-equilibrium data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:15.913250Z",
     "iopub.status.busy": "2020-10-26T12:13:15.912811Z",
     "iopub.status.idle": "2020-10-26T12:13:15.916010Z",
     "shell.execute_reply": "2020-10-26T12:13:15.915518Z"
    }
   },
   "outputs": [],
   "source": [
    "tica_model = tica.fit(feature_trajectory, lagtime=1).fetch_model()  # fit and fetch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the visualization of above and plot the projected data as well as the dominant slow direction, maximizing autocorrelation (instead of variance, cf PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:15.931323Z",
     "iopub.status.busy": "2020-10-26T12:13:15.930526Z",
     "iopub.status.idle": "2020-10-26T12:13:16.127803Z",
     "shell.execute_reply": "2020-10-26T12:13:16.127394Z"
    }
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1.plot(tica_model.transform(feature_trajectory))\n",
    "ax1.set_title('TICA projection of 2-dimensional trajectory')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('t')\n",
    "\n",
    "dxy = tica_model.singular_vectors_left[:, 0]  # dominant tica component\n",
    "\n",
    "ax2.scatter(*(feature_trajectory.T), marker='.')\n",
    "x, y = np.meshgrid(\n",
    "    np.linspace(np.min(feature_trajectory[:, 0]), np.max(feature_trajectory[:, 0]), 4),\n",
    "    np.linspace(np.min(feature_trajectory[:, 1]), np.max(feature_trajectory[:, 1]), 4)\n",
    ")\n",
    "plt.quiver(x, y, dxy[0], dxy[1])\n",
    "\n",
    "ax2.set_aspect('equal')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_title('Example data samples with dominant TICA component');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implied timescales of the tica model can be accessed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:16.131284Z",
     "iopub.status.busy": "2020-10-26T12:13:16.130755Z",
     "iopub.status.idle": "2020-10-26T12:13:16.133747Z",
     "shell.execute_reply": "2020-10-26T12:13:16.133347Z"
    }
   },
   "outputs": [],
   "source": [
    "tica_model.timescales(lagtime=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, one should expect as many timescales as\n",
    "input coordinates were available. However, fewer eigenvalues will be returned if the TICA matrices\n",
    "were not full rank or `dim` contained a floating point percentage, i.e., was interpreted as\n",
    "variance cutoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model also offers a function that yields an instantaneous correlation matrix between mean-free input features and TICs (i.e., the axes that are projected onto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:16.137298Z",
     "iopub.status.busy": "2020-10-26T12:13:16.136763Z",
     "iopub.status.idle": "2020-10-26T12:13:16.139914Z",
     "shell.execute_reply": "2020-10-26T12:13:16.139518Z"
    }
   },
   "outputs": [],
   "source": [
    "tica_model.feature_component_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In greater detail: Denoting the input features as $X_i$ and the TICs as $\\theta_j$, the instantaneous, linear\n",
    "correlation between them can be written as\n",
    "\n",
    "$$  \\mathbf{Corr}(X_i - \\mu_i, \\mathbf{\\theta}_j) = \\frac{1}{\\sigma_{X_i - \\mu_i}}\\sum_l \\sigma_{(X_i - \\mu_i)(X_l - \\mu_l)} \\mathbf{U}_{li}. $$\n",
    "\n",
    "The matrix $\\mathbf{U}$ is the matrix containing the eigenvectors of the TICA generalized eigenvalue problem as column vectors, i.e., there is a row for each feature and a column for each TIC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvector scaling\n",
    "\n",
    "The TICA estimator possesses a scaling parameter which can be used to introduce further properties to the projection. It can take the following values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`None`: No scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:16.143114Z",
     "iopub.status.busy": "2020-10-26T12:13:16.142722Z",
     "iopub.status.idle": "2020-10-26T12:13:16.145193Z",
     "shell.execute_reply": "2020-10-26T12:13:16.145499Z"
    }
   },
   "outputs": [],
   "source": [
    "tica.scaling = None\n",
    "tica_model = tica.fit(feature_trajectory, lagtime=1).fetch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\"kinetic_map\"` (default): Eigenvectors will be scaled by eigenvalues. As a result, Euclidean distances in the transformed data approximate kinetic distances <cite data-cite=\"nbtica-noe2015kinetic\">(Noé, 2015)</cite>. This is a good choice when the data is further processed by clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:16.149020Z",
     "iopub.status.busy": "2020-10-26T12:13:16.148159Z",
     "iopub.status.idle": "2020-10-26T12:13:16.151053Z",
     "shell.execute_reply": "2020-10-26T12:13:16.150654Z"
    }
   },
   "outputs": [],
   "source": [
    "tica.scaling = \"kinetic_map\"  # default\n",
    "tica_model_kinetic_map = tica.fit(feature_trajectory, lagtime=1).fetch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\"commute_map\"`: Eigenvector i will be scaled by $\\sqrt{\\mathrm{timescale}_i / 2}$. As a result, Euclidean distances in the transformed data will approximate commute distances <cite data-cite=\"nbtica-noe2016commute\">(Noé, 2016)</cite>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:16.154215Z",
     "iopub.status.busy": "2020-10-26T12:13:16.153781Z",
     "iopub.status.idle": "2020-10-26T12:13:16.156236Z",
     "shell.execute_reply": "2020-10-26T12:13:16.156540Z"
    }
   },
   "outputs": [],
   "source": [
    "tica.scaling = \"commute_map\"\n",
    "tica_model_commute_map = tica.fit(feature_trajectory, lagtime=1).fetch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the projections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:16.170175Z",
     "iopub.status.busy": "2020-10-26T12:13:16.169724Z",
     "iopub.status.idle": "2020-10-26T12:13:16.309102Z",
     "shell.execute_reply": "2020-10-26T12:13:16.308698Z"
    }
   },
   "outputs": [],
   "source": [
    "f, ax1 = plt.subplots(1, 1)\n",
    "ax1.plot(tica_model.transform(feature_trajectory), label=\"Unscaled\")\n",
    "ax1.plot(tica_model_kinetic_map.transform(feature_trajectory), label=\"Kinetic map\", alpha=.5)\n",
    "ax1.plot(tica_model_commute_map.transform(feature_trajectory), label=\"Commute map\")\n",
    "ax1.set_title('TICA projection of 2-dimensional trajectory with different eigenvector scalings')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('t')\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Koopman reweighting\n",
    "\n",
    "If the data that is used for estimation (for the most part) is not in equilibrium, the estimate can become heavily biased in case reversibility is enforced. Koopman reweighting <cite data-cite=\"nbtica-wu2017variational\">(Wu, 2017)</cite> assigns weights to each frame of the time series so that also off-equilibrium data can be used. In deeptime, a [Koopman weighting estimator](../api/generated/deeptime.covariance.KoopmanWeightingEstimator.rst#deeptime.covariance.KoopmanWeightingEstimator) is implemented, which learns appropriate weights from data. The corresponding [Koopman model](../api/generated/deeptime.covariance.KoopmanWeightingModel.rst#deeptime.covariance.KoopmanWeightingModel) can be used as an argument in TICA's `fit`.\n",
    "\n",
    "This reweighting technique becomes necessary as soon as the available data is not a single long trajectory which equilibrates and then is in an equilibrium state for the rest of the time but rather if many short and at least initially off-equilibrium trajectories are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:16.312188Z",
     "iopub.status.busy": "2020-10-26T12:13:16.311816Z",
     "iopub.status.idle": "2020-10-26T12:13:16.313686Z",
     "shell.execute_reply": "2020-10-26T12:13:16.313983Z"
    }
   },
   "outputs": [],
   "source": [
    "tica = deeptime.decomposition.TICA(lagtime=1, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:16.317160Z",
     "iopub.status.busy": "2020-10-26T12:13:16.316693Z",
     "iopub.status.idle": "2020-10-26T12:13:16.319239Z",
     "shell.execute_reply": "2020-10-26T12:13:16.318863Z"
    }
   },
   "outputs": [],
   "source": [
    "koopman_estimator = deeptime.covariance.KoopmanWeightingEstimator(lagtime=1)\n",
    "reweighting_model = koopman_estimator.fit(feature_trajectory).fetch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and fitting TICA using said weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:16.322264Z",
     "iopub.status.busy": "2020-10-26T12:13:16.321875Z",
     "iopub.status.idle": "2020-10-26T12:13:16.324465Z",
     "shell.execute_reply": "2020-10-26T12:13:16.324862Z"
    }
   },
   "outputs": [],
   "source": [
    "tica_model_reweighted = tica.fit(feature_trajectory, weights=reweighting_model) \\\n",
    "    .fetch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the results can be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T12:13:16.404027Z",
     "iopub.status.busy": "2020-10-26T12:13:16.389777Z",
     "iopub.status.idle": "2020-10-26T12:13:16.586601Z",
     "shell.execute_reply": "2020-10-26T12:13:16.586207Z"
    }
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1.plot(tica_model.transform(feature_trajectory))\n",
    "ax1.set_title('TICA projection of 2-dimensional trajectory')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('t')\n",
    "\n",
    "dxy = tica_model.singular_vectors_left[:, 0]  # dominant tica component\n",
    "\n",
    "ax2.scatter(*(feature_trajectory.T), marker='.')\n",
    "x, y = np.meshgrid(\n",
    "    np.linspace(np.min(feature_trajectory[:, 0]), np.max(feature_trajectory[:, 0]), 4),\n",
    "    np.linspace(np.min(feature_trajectory[:, 1]), np.max(feature_trajectory[:, 1]), 4)\n",
    ")\n",
    "plt.quiver(x, y, dxy[0], dxy[1])\n",
    "\n",
    "ax2.set_aspect('equal')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_title('Example data samples with dominant TICA component');"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. rubric:: References\n",
    "\n",
    ".. bibliography:: /references.bib\n",
    "    :style: unsrt\n",
    "    :filter: docname in docnames\n",
    "    :keyprefix: nbtica-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
